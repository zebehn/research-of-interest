# Research Of Interest

## 연구 주제

### 대화 기반 교류를 통해 작업, 제스처, 모션을 가르치는 방법

#### 참고자료

- Motion-Agent: A Conversational Framework for Human Motion Generation with LLMs ([arxiv](https://arxiv.org/abs/2405.17013), [pdf](https://openreview.net/pdf?id=AvOhBgsE5R))
- AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents ([homepage](https://anyskill.github.io))
- Learning from Human Instructions ([youtube](https://www.youtube.com/watch?v=p89PKaKirMs), [pdf](http://ai2-website.s3.amazonaws.com/publications/LearnByInst.pdf))

## 기타 주제

### Commonsense Reasoning
* [SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference](http://rowanzellers.com/swag/) [arxiv](https://arxiv.org/abs/1808.05326)

* [Commonsense Inference on Events, Intents and Reactions]() [arxiv]()

### Affect/Emotion/Sentiment Analysis
* [MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversation](https://github.com/SenticNet/MELD) [arxiv](https://arxiv.org/abs/1810.02508)

### Lifelong/Continual Learning
* [L2M Lifelong Learning Machines](https://www.darpa.mil/program/lifelong-learning-machines)

### Multimodal Machine Learning
* [See, Hear, and Read: Deep Aligned Representations](https://arxiv.org/abs/1706.00932)

### Datasets
* [AdobeIndoorNav Dataset](https://github.com/daerduoCarey/AdobeIndoorNav) - Dataset for robot visual navigation in real-world scenes [arxiv](https://arxiv.org/abs/1802.08824)

## Researchers
* [Carl Vondrick](http://www.cs.columbia.edu/~vondrick/) - The sound of pixel, 
Generating Videos with Scene Dynamics etc
